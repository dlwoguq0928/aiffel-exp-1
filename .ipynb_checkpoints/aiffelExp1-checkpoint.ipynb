{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c078cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from glob import iglob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebfad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Resizing Method\n",
    "def resize_images(img_path):\n",
    "\timages=glob(img_path + \"/*.png\")  \n",
    " \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    " \n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"PNG\")\n",
    "  \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\n",
    "# Data Loading Method\n",
    "def load_data(img_path, number_of_data=100):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=4\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in iglob(img_path+'/scissors/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1\n",
    "        idx=idx+1  \n",
    "\n",
    "    for file in iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2\n",
    "        idx=idx+1\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "359ba0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n",
      "840  images to be resized.\n",
      "840  images resized.\n",
      "840  images to be resized.\n",
      "840  images resized.\n",
      "124  images to be resized.\n",
      "124  images resized.\n",
      "124  images to be resized.\n",
      "124  images resized.\n",
      "124  images to be resized.\n",
      "124  images resized.\n"
     ]
    }
   ],
   "source": [
    "# Resize the Data Images : Train\n",
    "image_dir_path = \"dataset/train/scissors\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path =  \"dataset/train/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = \"dataset/train/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# Resize the Data Images : Test\n",
    "image_dir_path = \"dataset/test/scissors\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path =  \"dataset/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = \"dataset/test/paper\"\n",
    "resize_images(image_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ea9344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2520 입니다.\n",
      "x_train shape: (2520, 28, 28, 4)\n",
      "y_train shape: (2520,)\n",
      "학습데이터(x_train)의 이미지 개수는 372 입니다.\n",
      "x_test shape: (372, 28, 28, 4)\n",
      "y_test shape: (372,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset : Train\n",
    "image_dir_path = \"dataset/train\"\n",
    "x_train, y_train = load_data(image_dir_path, number_of_data=2520)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "# Load the Dataset : Test\n",
    "image_dir_path = \"dataset/test\"\n",
    "x_test, y_test = load_data(image_dir_path, number_of_data=372)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d06b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 8)         296       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 26,088\n",
      "Trainable params: 25,864\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 하이퍼 파라미터\n",
    "# kernel_regularizer = keras.regularizers.L1(0.001)\n",
    "kernel_regularizer = None\n",
    "\n",
    "# 모델 설계\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(28,28,4)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, (3,3), kernel_regularizer=kernel_regularizer))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3,3), kernel_regularizer=kernel_regularizer))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3,3), kernel_regularizer=kernel_regularizer))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='softmax'))\n",
    "\n",
    "# 모델 개요\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = 'adam'\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics = ['categorical_accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0020 - categorical_accuracy: 0.4762 - val_loss: 0.7562 - val_categorical_accuracy: 0.0053\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0021 - categorical_accuracy: 0.4768 - val_loss: 0.8227 - val_categorical_accuracy: 0.0053\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0020 - categorical_accuracy: 0.4762 - val_loss: 0.3362 - val_categorical_accuracy: 0.0635\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0183 - categorical_accuracy: 0.4785 - val_loss: 9.9391e-04 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0035 - categorical_accuracy: 0.4768 - val_loss: 0.1924 - val_categorical_accuracy: 0.0159\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0016 - categorical_accuracy: 0.4762 - val_loss: 0.1703 - val_categorical_accuracy: 0.0013\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0012 - categorical_accuracy: 0.4762 - val_loss: 0.7327 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0014 - categorical_accuracy: 0.4762 - val_loss: 0.6825 - val_categorical_accuracy: 0.0013\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0017 - categorical_accuracy: 0.4762 - val_loss: 0.5130 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0044 - categorical_accuracy: 0.4762 - val_loss: 1.1141 - val_categorical_accuracy: 0.0079\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0012 - categorical_accuracy: 0.4762 - val_loss: 0.7254 - val_categorical_accuracy: 0.0040\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 8.3573e-04 - categorical_accuracy: 0.4762 - val_loss: 0.8066 - val_categorical_accuracy: 0.0013\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.0529e-04 - categorical_accuracy: 0.4762 - val_loss: 0.7119 - val_categorical_accuracy: 0.0013\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 5.5447e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5493 - val_categorical_accuracy: 0.0013\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.9189e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5010 - val_categorical_accuracy: 0.0026\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 5.2437e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5161 - val_categorical_accuracy: 0.0026\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.8111e-04 - categorical_accuracy: 0.4762 - val_loss: 0.4385 - val_categorical_accuracy: 0.0013\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.0634e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5001 - val_categorical_accuracy: 0.0013\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.9963e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5020 - val_categorical_accuracy: 0.0013\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.5706e-04 - categorical_accuracy: 0.4762 - val_loss: 0.6350 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 4.6859e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3274 - val_categorical_accuracy: 0.0040\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.1255e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3657 - val_categorical_accuracy: 0.0026\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.5666e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3907 - val_categorical_accuracy: 0.0013\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.9276e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3387 - val_categorical_accuracy: 0.0026\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.2033e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3620 - val_categorical_accuracy: 0.0026\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.8925e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3444 - val_categorical_accuracy: 0.0026\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.3052e-04 - categorical_accuracy: 0.4762 - val_loss: 0.4253 - val_categorical_accuracy: 0.0013\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.7366e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2028 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 4.6010e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5621 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.8525e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5657 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.0717e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3801 - val_categorical_accuracy: 0.0079\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0041 - categorical_accuracy: 0.4762 - val_loss: 0.8057 - val_categorical_accuracy: 0.0966\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0036 - categorical_accuracy: 0.4773 - val_loss: 0.2621 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0017 - categorical_accuracy: 0.4762 - val_loss: 0.2905 - val_categorical_accuracy: 0.0066\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.0455e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5695 - val_categorical_accuracy: 0.0013\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.9698e-04 - categorical_accuracy: 0.4762 - val_loss: 0.4787 - val_categorical_accuracy: 0.0119\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.6722e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3832 - val_categorical_accuracy: 0.0093\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.1258e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3509 - val_categorical_accuracy: 0.0040\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.3904e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3308 - val_categorical_accuracy: 0.0066\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.8399e-04 - categorical_accuracy: 0.4762 - val_loss: 0.5068 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0225 - categorical_accuracy: 0.4762 - val_loss: 0.0014 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0015 - categorical_accuracy: 0.4762 - val_loss: 0.0115 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 9.2667e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2083 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 9.3488e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2939 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0011 - categorical_accuracy: 0.4762 - val_loss: 0.2114 - val_categorical_accuracy: 0.0291\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.7020e-04 - categorical_accuracy: 0.4762 - val_loss: 0.1267 - val_categorical_accuracy: 0.0093\n",
      "Epoch 47/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.6380e-04 - categorical_accuracy: 0.4762 - val_loss: 0.1589 - val_categorical_accuracy: 0.0132\n",
      "Epoch 48/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0011 - categorical_accuracy: 0.4762 - val_loss: 0.5116 - val_categorical_accuracy: 0.0675\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 6ms/step - loss: 2.8539e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3746 - val_categorical_accuracy: 0.0410\n",
      "Epoch 50/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.5115e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2390 - val_categorical_accuracy: 0.0410\n",
      "Epoch 51/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.1841e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2334 - val_categorical_accuracy: 0.0251\n",
      "Epoch 52/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.5667e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3160 - val_categorical_accuracy: 0.0198\n",
      "Epoch 53/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0489e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3258 - val_categorical_accuracy: 0.0198\n",
      "Epoch 54/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.3676e-04 - categorical_accuracy: 0.4762 - val_loss: 0.4642 - val_categorical_accuracy: 0.0106\n",
      "Epoch 55/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 8.3504e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3674 - val_categorical_accuracy: 0.0132\n",
      "Epoch 56/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0234e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3007 - val_categorical_accuracy: 0.0185\n",
      "Epoch 57/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 9.8794e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2798 - val_categorical_accuracy: 0.0132\n",
      "Epoch 58/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.2015e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3324 - val_categorical_accuracy: 0.0119\n",
      "Epoch 59/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.9771e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0879 - val_categorical_accuracy: 0.0093\n",
      "Epoch 60/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.2136e-04 - categorical_accuracy: 0.4762 - val_loss: 0.1164 - val_categorical_accuracy: 0.0132\n",
      "Epoch 61/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 8.0287e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2164 - val_categorical_accuracy: 0.0265\n",
      "Epoch 62/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 6.6325e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2677 - val_categorical_accuracy: 0.0251\n",
      "Epoch 63/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 5.0537e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3061 - val_categorical_accuracy: 0.0225\n",
      "Epoch 64/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 7.5047e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2500 - val_categorical_accuracy: 0.0172\n",
      "Epoch 65/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 5.6402e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2718 - val_categorical_accuracy: 0.0172\n",
      "Epoch 66/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 6.5092e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3416 - val_categorical_accuracy: 0.0079\n",
      "Epoch 67/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 6.0373e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3056 - val_categorical_accuracy: 0.0146\n",
      "Epoch 68/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 5.4287e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3117 - val_categorical_accuracy: 0.0225\n",
      "Epoch 69/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.5612e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2960 - val_categorical_accuracy: 0.0198\n",
      "Epoch 70/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.2781e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2863 - val_categorical_accuracy: 0.0159\n",
      "Epoch 71/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 4.0192e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2844 - val_categorical_accuracy: 0.0119\n",
      "Epoch 72/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.1648e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2639 - val_categorical_accuracy: 0.0106\n",
      "Epoch 73/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.1560e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2479 - val_categorical_accuracy: 0.0132\n",
      "Epoch 74/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.7394e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2664 - val_categorical_accuracy: 0.0040\n",
      "Epoch 75/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.7707e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2640 - val_categorical_accuracy: 0.0119\n",
      "Epoch 76/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.5492e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2607 - val_categorical_accuracy: 0.0119\n",
      "Epoch 77/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.9654e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2150 - val_categorical_accuracy: 0.0066\n",
      "Epoch 78/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.4039e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2195 - val_categorical_accuracy: 0.0013\n",
      "Epoch 79/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.3299e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2245 - val_categorical_accuracy: 0.0066\n",
      "Epoch 80/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.6290e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2044 - val_categorical_accuracy: 0.0106\n",
      "Epoch 81/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.2858e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2307 - val_categorical_accuracy: 0.0079\n",
      "Epoch 82/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.0430e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2553 - val_categorical_accuracy: 0.0106\n",
      "Epoch 83/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.4874e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2410 - val_categorical_accuracy: 0.0066\n",
      "Epoch 84/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.9669e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2320 - val_categorical_accuracy: 0.0066\n",
      "Epoch 85/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.1244e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2505 - val_categorical_accuracy: 0.0093\n",
      "Epoch 86/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.8538e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3326 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.5215e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2699 - val_categorical_accuracy: 0.0106\n",
      "Epoch 88/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.9170e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3959 - val_categorical_accuracy: 0.0185\n",
      "Epoch 89/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 5.7328e-05 - categorical_accuracy: 0.4762 - val_loss: 0.3050 - val_categorical_accuracy: 0.0079\n",
      "Epoch 90/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.0153e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2047 - val_categorical_accuracy: 0.0198\n",
      "Epoch 91/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.4274e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0877 - val_categorical_accuracy: 0.0066\n",
      "Epoch 92/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.5039e-05 - categorical_accuracy: 0.4762 - val_loss: 0.1363 - val_categorical_accuracy: 0.0132\n",
      "Epoch 93/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.1983e-05 - categorical_accuracy: 0.4762 - val_loss: 0.2022 - val_categorical_accuracy: 0.0159\n",
      "Epoch 94/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.3458e-05 - categorical_accuracy: 0.4762 - val_loss: 0.1945 - val_categorical_accuracy: 0.0066\n",
      "Epoch 95/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 5.5623e-05 - categorical_accuracy: 0.4762 - val_loss: 0.1571 - val_categorical_accuracy: 0.0093\n",
      "Epoch 96/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.3722e-05 - categorical_accuracy: 0.4762 - val_loss: 0.1188 - val_categorical_accuracy: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0024 - categorical_accuracy: 0.4762 - val_loss: 0.2438 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0102 - categorical_accuracy: 0.4768 - val_loss: 5.8391 - val_categorical_accuracy: 0.0159\n",
      "Epoch 99/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0027 - categorical_accuracy: 0.4762 - val_loss: 0.0358 - val_categorical_accuracy: 0.0013\n",
      "Epoch 100/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.5124e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0299 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.6525e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0692 - val_categorical_accuracy: 0.0026\n",
      "Epoch 102/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.6130e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0941 - val_categorical_accuracy: 0.0026\n",
      "Epoch 103/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.5563e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0723 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0675e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0934 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.2228e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0620 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0063 - categorical_accuracy: 0.4779 - val_loss: 0.8307 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.8616e-04 - categorical_accuracy: 0.4762 - val_loss: 0.7186 - val_categorical_accuracy: 0.0291\n",
      "Epoch 108/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.8029e-04 - categorical_accuracy: 0.4762 - val_loss: 0.3728 - val_categorical_accuracy: 0.0291\n",
      "Epoch 109/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.3323e-04 - categorical_accuracy: 0.4762 - val_loss: 0.1654 - val_categorical_accuracy: 0.0370\n",
      "Epoch 110/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.3748e-04 - categorical_accuracy: 0.4762 - val_loss: 0.2664 - val_categorical_accuracy: 0.0423\n",
      "Epoch 111/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.1627e-04 - categorical_accuracy: 0.4762 - val_loss: 0.1577 - val_categorical_accuracy: 0.0384\n",
      "Epoch 112/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.7189e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0940 - val_categorical_accuracy: 0.0291\n",
      "Epoch 113/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 4.8832e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0794 - val_categorical_accuracy: 0.0238\n",
      "Epoch 114/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0423e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0951 - val_categorical_accuracy: 0.0304\n",
      "Epoch 115/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.9488e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0737 - val_categorical_accuracy: 0.0238\n",
      "Epoch 116/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 8.1422e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0426 - val_categorical_accuracy: 0.0185\n",
      "Epoch 117/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.2524e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0608 - val_categorical_accuracy: 0.0225\n",
      "Epoch 118/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 4.1070e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0604 - val_categorical_accuracy: 0.0225\n",
      "Epoch 119/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.1395e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0587 - val_categorical_accuracy: 0.0225\n",
      "Epoch 120/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.4456e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0597 - val_categorical_accuracy: 0.0212\n",
      "Epoch 121/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.1029e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0591 - val_categorical_accuracy: 0.0212\n",
      "Epoch 122/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.2990e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0658 - val_categorical_accuracy: 0.0225\n",
      "Epoch 123/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.7121e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0447 - val_categorical_accuracy: 0.0159\n",
      "Epoch 124/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 8.0747e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0334 - val_categorical_accuracy: 0.0172\n",
      "Epoch 125/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.6195e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0454 - val_categorical_accuracy: 0.0198\n",
      "Epoch 126/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 3.4831e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0439 - val_categorical_accuracy: 0.0198\n",
      "Epoch 127/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.2832e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0511 - val_categorical_accuracy: 0.0225\n",
      "Epoch 128/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.2795e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0545 - val_categorical_accuracy: 0.0212\n",
      "Epoch 129/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.9519e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0433 - val_categorical_accuracy: 0.0172\n",
      "Epoch 130/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.1733e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0334 - val_categorical_accuracy: 0.0172\n",
      "Epoch 131/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.4565e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0376 - val_categorical_accuracy: 0.0172\n",
      "Epoch 132/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.7029e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0377 - val_categorical_accuracy: 0.0172\n",
      "Epoch 133/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.1782e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0384 - val_categorical_accuracy: 0.0172\n",
      "Epoch 134/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.3963e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0389 - val_categorical_accuracy: 0.0172\n",
      "Epoch 135/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.8166e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0409 - val_categorical_accuracy: 0.0159\n",
      "Epoch 136/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.5408e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0351 - val_categorical_accuracy: 0.0159\n",
      "Epoch 137/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 2.0330e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0296 - val_categorical_accuracy: 0.0146\n",
      "Epoch 138/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.2895e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0383 - val_categorical_accuracy: 0.0172\n",
      "Epoch 139/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.6185e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0370 - val_categorical_accuracy: 0.0159\n",
      "Epoch 140/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.1076e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0372 - val_categorical_accuracy: 0.0159\n",
      "Epoch 141/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 9.2343e-06 - categorical_accuracy: 0.4762 - val_loss: 0.0385 - val_categorical_accuracy: 0.0172\n",
      "Epoch 142/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.2364e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0372 - val_categorical_accuracy: 0.0172\n",
      "Epoch 143/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.4553e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0341 - val_categorical_accuracy: 0.0146\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 6ms/step - loss: 9.0502e-06 - categorical_accuracy: 0.4762 - val_loss: 0.0348 - val_categorical_accuracy: 0.0159\n",
      "Epoch 145/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 7.3563e-06 - categorical_accuracy: 0.4762 - val_loss: 0.0353 - val_categorical_accuracy: 0.0159\n",
      "Epoch 146/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.9574e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0291 - val_categorical_accuracy: 0.0066\n",
      "Epoch 147/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.6321e-04 - categorical_accuracy: 0.4762 - val_loss: 0.0094 - val_categorical_accuracy: 0.0013\n",
      "Epoch 148/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 3.4082e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0157 - val_categorical_accuracy: 0.0053\n",
      "Epoch 149/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.4461e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0196 - val_categorical_accuracy: 0.0093\n",
      "Epoch 150/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.9127e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0258 - val_categorical_accuracy: 0.0132\n",
      "Epoch 151/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.8105e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0275 - val_categorical_accuracy: 0.0132\n",
      "Epoch 152/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2.5524e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0378 - val_categorical_accuracy: 0.0159\n",
      "Epoch 153/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.4129e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0402 - val_categorical_accuracy: 0.0172\n",
      "Epoch 154/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.9516e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0203 - val_categorical_accuracy: 0.0066\n",
      "Epoch 155/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.6672e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0420 - val_categorical_accuracy: 0.0106\n",
      "Epoch 156/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.4063e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0396 - val_categorical_accuracy: 0.0146\n",
      "Epoch 157/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.7185e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0357 - val_categorical_accuracy: 0.0146\n",
      "Epoch 158/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.5522e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0346 - val_categorical_accuracy: 0.0146\n",
      "Epoch 159/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 6.2972e-06 - categorical_accuracy: 0.4762 - val_loss: 0.0430 - val_categorical_accuracy: 0.0172\n",
      "Epoch 160/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 5.8566e-06 - categorical_accuracy: 0.4762 - val_loss: 0.0451 - val_categorical_accuracy: 0.0172\n",
      "Epoch 161/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.5533e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0538 - val_categorical_accuracy: 0.0185\n",
      "Epoch 162/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 5.8603e-05 - categorical_accuracy: 0.4762 - val_loss: 0.0219 - val_categorical_accuracy: 0.0146\n",
      "Epoch 163/1000\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 1.9125e-05 - categorical_accuracy: 0.4775"
     ]
    }
   ],
   "source": [
    "# 콜백 지정\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train_norm, y_train, validation_split=0.3, epochs=1000)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fbace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
